{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 02 - Data Cleaning & Preprocessing\n",
                "\n",
                "Notebook này thực hiện làm sạch và preprocessing dữ liệu phim.\n",
                "\n",
                "## Mục Tiêu\n",
                "- Xử lý missing values\n",
                "- Loại bỏ duplicates\n",
                "- Xử lý outliers\n",
                "- Feature engineering\n",
                "- Text vectorization (TF-IDF)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Import Libraries"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "import os\n",
                "\n",
                "# Add src to path\n",
                "sys.path.append(os.path.abspath('../src'))\n",
                "\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "\n",
                "from data_processing.cleaner import MovieDataCleaner\n",
                "from data_processing.preprocessor import MovieDataPreprocessor\n",
                "\n",
                "# Set display options\n",
                "pd.set_option('display.max_columns', None)\n",
                "pd.set_option('display.max_rows', 100)\n",
                "\n",
                "# Set plot style\n",
                "sns.set_style('whitegrid')\n",
                "plt.rcParams['figure.figsize'] = (14, 6)\n",
                "\n",
                "print(\"✅ Libraries imported successfully\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Load Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load raw data\n",
                "data_dir = '../data/raw/ml-latest-small'\n",
                "\n",
                "movies = pd.read_csv(f'{data_dir}/movies.csv')\n",
                "ratings = pd.read_csv(f'{data_dir}/ratings.csv')\n",
                "tags = pd.read_csv(f'{data_dir}/tags.csv')\n",
                "links = pd.read_csv(f'{data_dir}/links.csv')\n",
                "\n",
                "print(f\"Loaded {len(movies)} movies, {len(ratings)} ratings, {len(tags)} tags\")\n",
                "print(f\"\\nMovies shape: {movies.shape}\")\n",
                "print(f\"Ratings shape: {ratings.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Data Quality Assessment"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "cleaner = MovieDataCleaner(verbose=True)\n",
                "\n",
                "print(\"=\" * 50)\n",
                "print(\"MISSING VALUES CHECK\")\n",
                "print(\"=\" * 50)\n",
                "\n",
                "print(\"\\nMovies:\")\n",
                "missing_movies = cleaner.check_missing_values(movies)\n",
                "if len(missing_movies) > 0:\n",
                "    print(missing_movies)\n",
                "else:\n",
                "    print(\"No missing values found\")\n",
                "\n",
                "print(\"\\nRatings:\")\n",
                "missing_ratings = cleaner.check_missing_values(ratings)\n",
                "if len(missing_ratings) > 0:\n",
                "    print(missing_ratings)\n",
                "else:\n",
                "    print(\"No missing values found\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"=\" * 50)\n",
                "print(\"DUPLICATES CHECK\")\n",
                "print(\"=\" * 50)\n",
                "\n",
                "print(f\"\\nMovies duplicates (by movieId): {movies['movieId'].duplicated().sum()}\")\n",
                "print(f\"Movies duplicates (all columns): {movies.duplicated().sum()}\")\n",
                "\n",
                "print(f\"\\nRatings duplicates (all columns): {ratings.duplicated().sum()}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"=\" * 50)\n",
                "print(\"DATA INFO\")\n",
                "print(\"=\" * 50)\n",
                "\n",
                "print(\"\\nMovies Info:\")\n",
                "movies.info()\n",
                "\n",
                "print(\"\\nRatings Info:\")\n",
                "ratings.info()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Clean Movies Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"=\" * 50)\n",
                "print(\"CLEANING MOVIES DATA\")\n",
                "print(\"=\" * 50)\n",
                "\n",
                "movies_clean = movies.copy()\n",
                "\n",
                "# 1. Remove duplicates nếu có\n",
                "if movies_clean.duplicated(subset=['movieId']).sum() > 0:\n",
                "    movies_clean = cleaner.remove_duplicates(movies_clean, subset=['movieId'])\n",
                "\n",
                "# 2. Handle missing genres (nếu có)\n",
                "if movies_clean['genres'].isnull().sum() > 0:\n",
                "    movies_clean = cleaner.handle_missing_values(\n",
                "        movies_clean, \n",
                "        strategy='constant', \n",
                "        columns=['genres'], \n",
                "        fill_value='(no genres listed)'\n",
                "    )\n",
                "\n",
                "print(f\"\\nCleaned movies: {len(movies_clean)} rows\")\n",
                "movies_clean.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Feature Engineering - Movies"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"=\" * 50)\n",
                "print(\"FEATURE ENGINEERING\")\n",
                "print(\"=\" * 50)\n",
                "\n",
                "preprocessor = MovieDataPreprocessor(verbose=True)\n",
                "\n",
                "# 1. Extract year from title\n",
                "movies_clean = preprocessor.extract_year_from_title(movies_clean)\n",
                "\n",
                "# 2. Clean title (remove year)\n",
                "movies_clean = preprocessor.clean_title(movies_clean)\n",
                "\n",
                "# 3. Parse genres\n",
                "movies_clean = preprocessor.parse_genres(movies_clean)\n",
                "\n",
                "# 4. Create genre features\n",
                "movies_clean = preprocessor.create_genre_features(movies_clean)\n",
                "\n",
                "# 5. Create temporal features\n",
                "movies_clean = preprocessor.create_temporal_features(movies_clean)\n",
                "\n",
                "print(\"\\nNew columns added:\")\n",
                "new_cols = [col for col in movies_clean.columns if col not in movies.columns]\n",
                "print(new_cols)\n",
                "\n",
                "movies_clean.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Add Rating Features"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"=\" * 50)\n",
                "print(\"RATING FEATURES\")\n",
                "print(\"=\" * 50)\n",
                "\n",
                "# Create rating features\n",
                "movies_enriched = preprocessor.create_rating_features(movies_clean, ratings)\n",
                "\n",
                "print(\"\\nRating features added:\")\n",
                "rating_cols = ['avg_rating', 'std_rating', 'num_ratings', 'popularity', 'rating_confidence']\n",
                "print(rating_cols)\n",
                "\n",
                "print(\"\\nSample with rating features:\")\n",
                "movies_enriched[['title_clean', 'year', 'avg_rating', 'num_ratings', 'popularity']].head(10)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Handle Outliers in Ratings"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"=\" * 50)\n",
                "print(\"OUTLIER DETECTION\")\n",
                "print(\"=\" * 50)\n",
                "\n",
                "# Check for outliers in num_ratings\n",
                "outliers = cleaner.detect_outliers_iqr(movies_enriched, 'num_ratings')\n",
                "\n",
                "print(f\"\\nMovies with outlier rating counts:\")\n",
                "print(movies_enriched[outliers][['title_clean', 'year', 'num_ratings', 'avg_rating']].sort_values('num_ratings', ascending=False).head(10))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize rating distribution\n",
                "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
                "\n",
                "# Histogram of num_ratings\n",
                "axes[0].hist(movies_enriched['num_ratings'], bins=50, edgecolor='black')\n",
                "axes[0].set_xlabel('Number of Ratings')\n",
                "axes[0].set_ylabel('Frequency')\n",
                "axes[0].set_title('Distribution of Rating Counts')\n",
                "axes[0].set_yscale('log')\n",
                "\n",
                "# Boxplot\n",
                "axes[1].boxplot(movies_enriched['num_ratings'])\n",
                "axes[1].set_ylabel('Number of Ratings')\n",
                "axes[1].set_title('Boxplot of Rating Counts')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "print(\"\\nNote: Outliers are expected (popular movies have many more ratings)\")\n",
                "print(\"We will NOT remove these outliers as they represent real popular movies.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Text Vectorization (TF-IDF)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"=\" * 50)\n",
                "print(\"TEXT VECTORIZATION\")\n",
                "print(\"=\" * 50)\n",
                "\n",
                "# Create combined features (title + genres)\n",
                "movies_enriched = preprocessor.create_combined_text_features(\n",
                "    movies_enriched, \n",
                "    columns=['title_clean', 'genres']\n",
                ")\n",
                "\n",
                "print(\"\\nSample combined features:\")\n",
                "print(movies_enriched[['title_clean', 'genres', 'combined_features']].head())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# TF-IDF vectorization\n",
                "tfidf_matrix, tfidf_vectorizer = preprocessor.vectorize_text_tfidf(\n",
                "    movies_enriched['combined_features'],\n",
                "    max_features=200,\n",
                "    ngram_range=(1, 2)\n",
                ")\n",
                "\n",
                "print(f\"\\nTF-IDF matrix shape: {tfidf_matrix.shape}\")\n",
                "print(f\"Number of features: {len(tfidf_vectorizer.get_feature_names_out())}\")\n",
                "\n",
                "print(\"\\nTop 20 TF-IDF features:\")\n",
                "print(tfidf_vectorizer.get_feature_names_out()[:20])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. One-Hot Encode Genres"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"=\" * 50)\n",
                "print(\"ONE-HOT ENCODING GENRES\")\n",
                "print(\"=\" * 50)\n",
                "\n",
                "# One-hot encode genres\n",
                "movies_with_genres, mlb = preprocessor.encode_genres_onehot(movies_enriched)\n",
                "\n",
                "print(f\"\\nGenres one-hot encoded: {len(mlb.classes_)}\")\n",
                "print(f\"Genre classes: {mlb.classes_}\")\n",
                "\n",
                "print(\"\\nSample with genre encoding:\")\n",
                "genre_cols = [col for col in movies_with_genres.columns if col.startswith('genre_')]\n",
                "movies_with_genres[['title_clean'] + genre_cols[:5]].head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 10. Data Summary"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"=\" * 50)\n",
                "print(\"FINAL DATASET SUMMARY\")\n",
                "print(\"=\" * 50)\n",
                "\n",
                "print(f\"\\nTotal movies: {len(movies_enriched)}\")\n",
                "print(f\"Total columns: {len(movies_enriched.columns)}\")\n",
                "\n",
                "print(\"\\nColumn groups:\")\n",
                "print(f\"  Original: movieId, title, genres\")\n",
                "print(f\"  Extracted: year, title_clean\")\n",
                "print(f\"  Genre features: {len([c for c in movies_enriched.columns if c.startswith('is_')])}\")\n",
                "print(f\"  Rating features: avg_rating, std_rating, num_ratings, popularity, rating_confidence\")\n",
                "print(f\"  Temporal features: movie_age, decade, era\")\n",
                "\n",
                "print(\"\\nMissing values after cleaning:\")\n",
                "missing_final = cleaner.check_missing_values(movies_enriched)\n",
                "if len(missing_final) > 0:\n",
                "    print(missing_final)\n",
                "else:\n",
                "    print(\"No missing values!\")\n",
                "\n",
                "print(\"\\nData quality:\")\n",
                "print(f\"  Duplicates: {movies_enriched.duplicated().sum()}\")\n",
                "print(f\"  Movies with ratings: {(movies_enriched['num_ratings'] > 0).sum()}\")\n",
                "print(f\"  Movies with year: {movies_enriched['year'].notna().sum()}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 11. Save Processed Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create processed directory\n",
                "processed_dir = '../data/processed'\n",
                "os.makedirs(processed_dir, exist_ok=True)\n",
                "\n",
                "# Save movies enriched\n",
                "movies_file = os.path.join(processed_dir, 'movies_enriched.csv')\n",
                "movies_enriched.to_csv(movies_file, index=False)\n",
                "print(f\"✅ Saved: {movies_file}\")\n",
                "\n",
                "# Save movies with one-hot genres (for some models)\n",
                "movies_genres_file = os.path.join(processed_dir, 'movies_with_genres.csv')\n",
                "movies_with_genres.to_csv(movies_genres_file, index=False)\n",
                "print(f\"✅ Saved: {movies_genres_file}\")\n",
                "\n",
                "# Save ratings (copy to processed)\n",
                "ratings_file = os.path.join(processed_dir, 'ratings.csv')\n",
                "ratings.to_csv(ratings_file, index=False)\n",
                "print(f\"✅ Saved: {ratings_file}\")\n",
                "\n",
                "# Save TF-IDF matrix\n",
                "import pickle\n",
                "tfidf_file = os.path.join(processed_dir, 'tfidf_matrix.pkl')\n",
                "with open(tfidf_file, 'wb') as f:\n",
                "    pickle.dump({\n",
                "        'matrix': tfidf_matrix,\n",
                "        'vectorizer': tfidf_vectorizer\n",
                "    }, f)\n",
                "print(f\"✅ Saved: {tfidf_file}\")\n",
                "\n",
                "print(\"\\n\" + \"=\" * 50)\n",
                "print(\"✅ DATA CLEANING & PREPROCESSING COMPLETED!\")\n",
                "print(\"=\" * 50)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Summary\n",
                "\n",
                "### Completed Tasks:\n",
                "1. ✅ **Missing Values**: Checked and handled (none found in MovieLens)\n",
                "2. ✅ **Duplicates**: Checked and removed if any\n",
                "3. ✅ **Outliers**: Detected in rating counts (kept as they represent popular movies)\n",
                "4. ✅ **Feature Engineering**:\n",
                "   - Extracted year from title\n",
                "   - Parsed genres\n",
                "   - Created genre features (binary)\n",
                "   - Created rating features (avg, std, count, popularity)\n",
                "   - Created temporal features (age, decade, era)\n",
                "5. ✅ **Text Vectorization**:\n",
                "   - TF-IDF on combined features (title + genres)\n",
                "   - One-hot encoding for genres\n",
                "\n",
                "### Files Created:\n",
                "- `data/processed/movies_enriched.csv` - Main dataset with all features\n",
                "- `data/processed/movies_with_genres.csv` - Dataset with one-hot encoded genres\n",
                "- `data/processed/ratings.csv` - Ratings data\n",
                "- `data/processed/tfidf_matrix.pkl` - TF-IDF matrix and vectorizer\n",
                "\n",
                "### Next Steps:\n",
                "- Phase 3: EDA & Visualization\n",
                "- Phase 4: Model Building"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "version": "3.8.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
